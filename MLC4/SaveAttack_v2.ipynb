{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\635718\\\\Desktop\\\\DataScience\\\\HackerEarth\\\\MLC4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_test = test['connection_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['cont_11','cont_12','cont_13','cont_17']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['cont_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['target'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='cat_9',y='cat_22',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(n_estimators=100, max_depth=3, min_samples_leaf=4, max_features=0.2, random_state=0)\n",
    "gb.fit(train.drop(['connection_id', 'target'],axis=1), train.target)\n",
    "features = train.drop(['connection_id', 'target'],axis=1).columns.values\n",
    "print(\"----- Training Done -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = (list(x) for x in zip(*sorted(zip(gb.feature_importances_, features), \n",
    "                                                            reverse = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb.feature_importances_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(features)\n",
    "feature_imp.columns = ['feature']\n",
    "feature_imp['imp'] = gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.sort_values(by='imp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#correlation matrix\n",
    "corrmat = train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='feature',y='imp',data=feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['cat_20','cont_3','cat_2','cont_2','cat_22','cont_14','cont_12','cat_23','cat_3','cont_11','cat_9',\n",
    "            'cont_13','cat_21','cat_7','cat_1','cont_1','cont_17','cont_8','cont_9','cont_18','cat_8','cont_10',\n",
    "            'cont_15','cat_5','cat_10','cont_16','cont_5','cont_4','cont_7','cont_6','cat_19','cat_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = [x for x in train.columns if x not in ['connection_id','target']]\n",
    "\n",
    "X = train[train_features].values\n",
    "y = train.loc[:,'target'].values\n",
    "T = test[train_features].values\n",
    "\n",
    "#create the models\n",
    "# LightGBM params\n",
    "lgb_params_1 = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 1250,\n",
    "    'max_bin': 10,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 10,\n",
    "    'colsample_bytree': 0.8, \n",
    "    'min_child_samples': 500\n",
    "}\n",
    "\n",
    "lgb_params_2 = {\n",
    "    'learning_rate': 0.005,\n",
    "    'n_estimators': 3700,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 2,\n",
    "    'colsample_bytree': 0.3,  \n",
    "    'num_leaves': 16\n",
    "}\n",
    "\n",
    "lgb_params_3 = {\n",
    "   'objective':'binary:logistic',\n",
    "   'learning_rate':0.02,\n",
    "    'n_estimators':1000,\n",
    "    'max_depth':4,\n",
    "    'subsample':0.9,\n",
    "    'colsample_bytree':0.9,  \n",
    "    'min_child_weight':10\n",
    "}\n",
    "\n",
    "lgb_model_1 = LGBMClassifier(**lgb_params_1)\n",
    "lgb_model_2 = LGBMClassifier(**lgb_params_2)\n",
    "lgb_model_3 = XGBClassifier(**lgb_params_3)\n",
    "#base_models = (lgb_model_1, lgb_model_2, lgb_model_3)\n",
    "base_models = (lgb_model_1, lgb_model_2)\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "stacker = log_model\n",
    "print(\"models created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models created\n"
     ]
    }
   ],
   "source": [
    "#train_features = features\n",
    "train_features = [x for x in train.columns if x not in ['connection_id','target']]\n",
    "\n",
    "X = train[train_features].values\n",
    "y = train.loc[:,'target'].values\n",
    "T = test[train_features].values\n",
    "\n",
    "param_1 = {\"n_estimators\": 400,\n",
    "            \"max_depth\": 1,\n",
    "            \"min_samples_split\": 0.1,\n",
    "            \"min_samples_leaf\": 1,\n",
    "            \"max_leaf_nodes\": 2,\n",
    "            \"min_weight_fraction_leaf\": 0.2\n",
    "}\n",
    "\n",
    "param_2 = {\"n_estimators\": 800,\n",
    "            \"max_depth\": 5,\n",
    "            \"min_samples_split\": 0.4,\n",
    "            \"min_samples_leaf\": 4,\n",
    "            \"max_leaf_nodes\": 10,\n",
    "            \"min_weight_fraction_leaf\": 0.3\n",
    "}\n",
    "\n",
    "param_3 = {\"n_estimators\": 300,\n",
    "            \"max_depth\": 7,\n",
    "            \"min_samples_split\": 0.5,\n",
    "            \"min_samples_leaf\": 10,\n",
    "            \"max_leaf_nodes\": 7,\n",
    "            \"min_weight_fraction_leaf\": 0.4\n",
    "}\n",
    "\n",
    "#clf1 = RandomForestClassifier(**param_1)\n",
    "#clf2 = RandomForestClassifier(**param_2)\n",
    "#clf3 = RandomForestClassifier(**param_3)\n",
    "\n",
    "lgb_params_3 = {\n",
    "   'learning_rate':0.02,\n",
    "    'n_estimators':100,\n",
    "    'max_depth':4,\n",
    "    'subsample':0.9,\n",
    "    'colsample_bytree':0.9,  \n",
    "    'min_child_weight':10\n",
    "}\n",
    "\n",
    "clf1 = XGBClassifier(**lgb_params_3)\n",
    "clf2 = XGBClassifier(**lgb_params_3)\n",
    "clf3 = XGBClassifier(**lgb_params_3)\n",
    "\n",
    "base_models = (clf1, clf2, clf3)\n",
    "\n",
    "print(\"models created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112871, 41)\n",
      "Fit XGBClassifier fold 1\n",
      "(112871, 41)\n",
      "Fit XGBClassifier fold 2\n",
      "(112872, 41)\n",
      "Fit XGBClassifier fold 3\n",
      "(112871, 41)\n",
      "Fit XGBClassifier fold 1\n",
      "(112871, 41)\n",
      "Fit XGBClassifier fold 2\n",
      "(112872, 41)\n",
      "Fit XGBClassifier fold 3\n",
      "(112871, 41)\n",
      "Fit XGBClassifier fold 1\n",
      "(112871, 41)\n",
      "Fit XGBClassifier fold 2\n",
      "(112872, 41)\n",
      "Fit XGBClassifier fold 3\n"
     ]
    }
   ],
   "source": [
    "#now we have the data with equal set of positives and negatives\n",
    "#lets check cross validation scores\n",
    "from scipy.stats import mode\n",
    "n_splits=3\n",
    "folds = list(StratifiedKFold(n_splits, shuffle=True, random_state=10).split(X, y))\n",
    "S_train = np.zeros((X.shape[0], len(base_models)))\n",
    "S_test = np.zeros((T.shape[0], len(base_models)))\n",
    "\n",
    "for i, clf in enumerate(base_models):\n",
    "    S_test_i = np.zeros((T.shape[0], n_splits))\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        X_train = X[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_holdout = X[test_idx]\n",
    "        print(X_train.shape)\n",
    "        \n",
    "        # Get positive examples\n",
    "        \"\"\"pos_1 = pd.Series(y_train == 1)\n",
    "        pos_2 = pd.Series(y_train == 2)\n",
    "        # Add positive examples - 1\n",
    "        X_train = pd.concat([pd.DataFrame(X_train), pd.DataFrame(X_train[pos_1])])\n",
    "        y_train = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_train[pos_1])])\n",
    "        # Add positive examples - 2\n",
    "        X_train = pd.concat([pd.DataFrame(X_train), pd.DataFrame(X_train[pos_2])])\n",
    "        y_train = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_train[pos_2])])\n",
    "        \n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(X_train))\n",
    "        np.random.shuffle(idx)\n",
    "        X_train = X_train.iloc[idx]\n",
    "        y_train = y_train.iloc[idx]\"\"\"\n",
    "\n",
    "        print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_holdout)\n",
    "        #y_pred = clf.predict_proba(X_holdout)[:,1]  \n",
    "        \n",
    "        S_train[test_idx, i] = y_pred\n",
    "        S_test_i[:, j] = clf.predict(T)\n",
    "        #S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "    \n",
    "    #print(S_test_i)\n",
    "    #print(mode(S_test_i, axis=1)[0].flatten())\n",
    "    #print(S_test_i.mean(axis=1))\n",
    "    S_test[:, i] = mode(S_test_i, axis=1)[0].flatten()\n",
    "    #S_test[:, i] = S_test_i.mean(axis=1)\n",
    "    #sns.distplot(S_test[:, i],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "clf = RandomForestClassifier()\n",
    "param_grid = {\"n_estimators\": [100,200,300],\n",
    "              \"max_depth\": [1,5,10],\n",
    "              \"min_samples_split\": [0.1,0.3,0.5,0.7],\n",
    "              \"min_samples_leaf\": [1,5,7,9],\n",
    "              \"max_leaf_nodes\": [2,5,7,9],\n",
    "              \"min_weight_fraction_leaf\": [0.1,0.2,0.3,0.4]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10)\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacker score: 0.77877\n",
      "[ 0.77942827  0.77836513  0.77857185  0.77918549  0.77829297]\n",
      "[1 0 0 ..., 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rf_params = {\n",
    "    'n_estimators':500,\n",
    "    'max_depth':4,\n",
    "    \"min_samples_split\": 6,\n",
    "    \"min_samples_leaf\": 10,\n",
    "    \"max_leaf_nodes\": 10,\n",
    "    \"min_weight_fraction_leaf\": 0.3\n",
    "}\"\"\"\n",
    "\n",
    "stacker = RandomForestClassifier()\n",
    "\n",
    "results = cross_val_score(stacker, S_train, y, cv=5)\n",
    "print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "print(results)\n",
    "\n",
    "#print(stacker.best_params_)\n",
    "\n",
    "#print(\"S train size is : \", S_train.shape)\n",
    "stacker.fit(S_train, y)\n",
    "res = stacker.predict(S_test)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(res))\n",
    "print(len(id_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(res,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(res)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = res\n",
    "sub.to_csv('stacked_result_strat_upsample.csv', index=False)\n",
    "\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
