{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./FraudTransaction/train.csv', nrows=100000)\n",
    "#test = pd.read_csv('./FraudTransaction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['target'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_id', 'num_var_1', 'num_var_2', 'num_var_3', 'num_var_4',\n",
       "       'num_var_5', 'num_var_6', 'num_var_7', 'cat_var_1', 'cat_var_2',\n",
       "       'cat_var_3', 'cat_var_4', 'cat_var_5', 'cat_var_6', 'cat_var_7',\n",
       "       'cat_var_8', 'cat_var_9', 'cat_var_10', 'cat_var_11', 'cat_var_12',\n",
       "       'cat_var_13', 'cat_var_14', 'cat_var_15', 'cat_var_16', 'cat_var_17',\n",
       "       'cat_var_18', 'cat_var_19', 'cat_var_20', 'cat_var_21', 'cat_var_22',\n",
       "       'cat_var_23', 'cat_var_24', 'cat_var_25', 'cat_var_26', 'cat_var_27',\n",
       "       'cat_var_28', 'cat_var_29', 'cat_var_30', 'cat_var_31', 'cat_var_32',\n",
       "       'cat_var_33', 'cat_var_34', 'cat_var_35', 'cat_var_36', 'cat_var_37',\n",
       "       'cat_var_38', 'cat_var_39', 'cat_var_40', 'cat_var_41', 'cat_var_42',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Data\n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_var_1 -- gf\n",
    "#cat_var_3 -- qt\n",
    "#cat_var_8 -- dn\n",
    "train['cat_var_1'].fillna(value='gf',inplace=True)\n",
    "train['cat_var_3'].fillna(value='qt',inplace=True)\n",
    "train['cat_var_8'].fillna(value='dn',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89317 35726\n",
      "0.399991043138\n"
     ]
    }
   ],
   "source": [
    "count_class_0, count_class_1 = train.target.value_counts()\n",
    "print(count_class_0, count_class_1)\n",
    "print(count_class_1/count_class_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35726.800000000003"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(count_class_0*2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125043, 51)\n"
     ]
    }
   ],
   "source": [
    "#Resample the data\n",
    "# Class count\n",
    "count_class_0, count_class_1 = train.target.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = train[train['target'] == 0]\n",
    "df_class_1 = train[train['target'] == 1]\n",
    "\n",
    "df_class_1_over = df_class_1.sample(int((count_class_0*2)/5), replace=True)\n",
    "\n",
    "train_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "# Shuffle data\n",
    "idx = np.arange(len(train_over))\n",
    "np.random.shuffle(idx)\n",
    "train_over = train_over.iloc[idx]\n",
    "\n",
    "train = train_over\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [x for x in train.columns if x.startswith('cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = [x for x in train.columns if x not in ['transaction_id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the data\n",
    "for column in train_features:\n",
    "    if train[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train[column])\n",
    "        train[column] = le.transform(train[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_dummies = pd.get_dummies(train, columns = cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_dummies['cat_var_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[train_features].values\n",
    "y = train.loc[:,'target'].values\n",
    "#T = test[train_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93021103  0.92769552  0.93053278  0.92984304  0.93037961]\n",
      "Stacker score: 0.9297323940086073 \n"
     ]
    }
   ],
   "source": [
    "stacker = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "results = cross_val_score(stacker, X, y, cv=5, scoring='roc_auc')\n",
    "print(results)\n",
    "print(\"Stacker score: {} \".format(results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72867825  0.73225522  0.73645648  0.74186676  0.73841452]\n",
      "Stacker score: 0.7355342464391806 for num: \n"
     ]
    }
   ],
   "source": [
    "stacker = XGBClassifier(n_estimators=150,seed=0)\n",
    "results = cross_val_score(stacker, X, y, cv=5, scoring='roc_auc')\n",
    "print(results)\n",
    "print(\"Stacker score: {} for num: \".format(results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the feature importance using XGB\n",
    "features = train_features\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators':200,\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'binary:logistic',\n",
    "    'min_child_weight':1,\n",
    "    'silent': 1,\n",
    "    'seed':0,\n",
    "    'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "x_Train, x_Test, y_Train, y_Test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_Train,y_Train, feature_names=features)\n",
    "xgtest = xgb.DMatrix(x_Test,y_Test, feature_names=features)\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "num_rounds = 100 # Increase the number of rounds while running in local\n",
    "model = xgb.train(xgb_params, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=5)\n",
    "\n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = RandomForestClassifier(n_estimators=200, max_depth=3, min_samples_leaf=4, max_features=0.2, random_state=0)\n",
    "gb.fit(train[train_features], train.target)\n",
    "features = train[train_features].columns.values\n",
    "print(\"----- Training Done -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = (list(x) for x in zip(*sorted(zip(gb.feature_importances_, features), \n",
    "                                                            reverse = False)))\n",
    "feature_imp = pd.DataFrame(features)\n",
    "feature_imp.columns = ['feature']\n",
    "feature_imp['imp'] = gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.sort_values(by='imp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(feature_imp.sort_values(by='imp',ascending=False)['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['num_var_4', 'cat_var_14', 'cat_var_2', 'cat_var_13', 'num_var_7', 'num_var_2', 'cat_var_15', 'cat_var_17',\n",
    "             'num_var_6', 'cat_var_18', 'cat_var_6', 'cat_var_12', 'num_var_1', 'cat_var_4', 'cat_var_20', 'cat_var_19',\n",
    "             'num_var_5', 'cat_var_24', 'cat_var_21', 'cat_var_5', 'cat_var_7', 'cat_var_22', 'cat_var_16', 'cat_var_26',\n",
    "            'cat_var_9', 'cat_var_30', 'cat_var_29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[features].values\n",
    "y = train.loc[:,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = RandomForestClassifier(n_estimators=150,random_state=0)\n",
    "results = cross_val_score(stacker, X, y, cv=5, scoring='roc_auc')\n",
    "print(results)\n",
    "print(\"Stacker score: {} for num: \".format(results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = XGBClassifier(n_estimators=350,seed=0)\n",
    "results = cross_val_score(stacker, X, y, cv=5, scoring='roc_auc')\n",
    "print(results)\n",
    "print(\"Stacker score: {} for num: \".format(results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['cat_var_2'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='num_var_4',y='target',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cat_var_1'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_var_1 -- gf\n",
    "#cat_var_3 -- qt\n",
    "#cat_var_8 -- dn\n",
    "train['cat_var_8'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cat_var_37'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "data_scaled = pd.DataFrame(preprocessing.scale(X),columns = features) \n",
    "\n",
    "pca.fit(X)\n",
    "\n",
    "#The amount of variance that each PC explains\n",
    "var = pca.explained_variance_ratio_\n",
    "\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
